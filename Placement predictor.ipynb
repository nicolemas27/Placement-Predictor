{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2925b2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0b48aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_excel('01 Train Data.xlsx')\n",
    "test_data = pd.read_excel('02 Test Data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d473eb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.dropna(axis=1, how='all')\n",
    "test_data = test_data.dropna(axis=1, how='all')\n",
    "\n",
    "# Remove duplicate rows \n",
    "train_data.drop_duplicates(subset=['First Name', 'Email ID'], keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ac12a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.dropna(subset=['Placement Status'])\n",
    "train_data['Placement Status'] = train_data['Placement Status'].map({'Placed': 1, 'Not placed': 0})\n",
    "\n",
    "selected_features = ['CGPA', 'Speaking Skills', 'ML Knowledge']\n",
    "\n",
    "# Perform one-hot encoding for the 'College Name' column\n",
    "train_data = pd.get_dummies(train_data, columns=['College Name'], drop_first=True)\n",
    "test_data = pd.get_dummies(test_data, columns=['College Name'], drop_first=True)\n",
    "\n",
    "train_data.dropna(subset=selected_features, inplace=True)\n",
    "\n",
    "X_train = train_data[selected_features]\n",
    "y_train = train_data['Placement Status']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4434825",
   "metadata": {},
   "source": [
    "## Random Forest (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "615e5ee2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nicole Mascarenhas\\AppData\\Local\\Temp\\ipykernel_30540\\1380317716.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  result_df['Placement Prediction'] = y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier \n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Feature selection and preprocessing for the test data\n",
    "X_test = test_data[selected_features]\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "result_df = test_data[['First Name', 'Email ID']]\n",
    "result_df['Placement Prediction'] = y_pred\n",
    "\n",
    "result_df.to_excel('Test_Data_with_Predictions_rf.xlsx', index=False)\n",
    "\n",
    "# Display the accuracy of the model on the training data\n",
    "y_train_pred = model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(f'Training Accuracy: {train_accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dba375",
   "metadata": {},
   "source": [
    " ## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3b62133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.67\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Train a Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "X_test = test_data[selected_features]\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(f'Training Accuracy: {train_accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58e77d0",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0db19e08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nicole Mascarenhas\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Nicole Mascarenhas\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Train a k-NN classifier\n",
    "k = 3  \n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn_classifier.predict(X_test)\n",
    "\n",
    "y_train_pred = knn_classifier.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(f'Training Accuracy: {train_accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0691e8bb",
   "metadata": {},
   "source": [
    "## Gradient Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df2fa0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.71\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# Create a Gradient Boosting Classifier\n",
    "model = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(f'Training Accuracy: {train_accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcaddf1",
   "metadata": {},
   "source": [
    "## XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e116811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.74\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Create an XGBoost Classifier\n",
    "model = xgb.XGBClassifier(random_state=42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(f'Training Accuracy: {train_accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f6e52c",
   "metadata": {},
   "source": [
    "## Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "022476c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 2s 28ms/step - loss: 0.6830 - accuracy: 0.5764 - val_loss: 0.6411 - val_accuracy: 0.7070\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.6448 - accuracy: 0.6608 - val_loss: 0.6202 - val_accuracy: 0.7070\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6435 - accuracy: 0.6608 - val_loss: 0.6182 - val_accuracy: 0.7070\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.6408 - accuracy: 0.6608 - val_loss: 0.6188 - val_accuracy: 0.7070\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.6398 - accuracy: 0.6608 - val_loss: 0.6183 - val_accuracy: 0.7070\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.6378 - accuracy: 0.6608 - val_loss: 0.6162 - val_accuracy: 0.7070\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.6364 - accuracy: 0.6608 - val_loss: 0.6173 - val_accuracy: 0.7070\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.6366 - accuracy: 0.6608 - val_loss: 0.6182 - val_accuracy: 0.7070\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.6348 - accuracy: 0.6608 - val_loss: 0.6145 - val_accuracy: 0.7070\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.6353 - accuracy: 0.6608 - val_loss: 0.6158 - val_accuracy: 0.7070\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "Training Accuracy: 0.66\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features if necessary\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Build and compile the neural network model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model using the training and validation data\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "\n",
    "# Display the accuracy of the model\n",
    "y_train_pred = (model.predict(X_train) > 0.5).astype(int)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(f'Training Accuracy: {train_accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465481df",
   "metadata": {},
   "source": [
    "## Comparing models to find Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cb2cf16",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Training Accuracy: 0.75\n",
      "Logistic Regression Training Accuracy: 0.66\n",
      "K-Nearest Neighbors Training Accuracy: 0.69\n",
      "Gradient Boosting Training Accuracy: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nicole Mascarenhas\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Training Accuracy: 0.74\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "Neural Network Training Accuracy: 0.66\n",
      "\n",
      "Selected Model: Random Forest (Training Accuracy: 0.75)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define a dictionary of models\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=3),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'XGBoost': xgb.XGBClassifier(random_state=42),\n",
    "    'Neural Network': model\n",
    "}\n",
    "\n",
    "# Calculate and print training accuracies\n",
    "model_accuracies = {}\n",
    "for model_name, model in models.items():\n",
    "    if model_name == 'Neural Network':\n",
    "        y_train_pred = (model.predict(X_train) > 0.5).astype(int)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_train_pred = model.predict(X_train)\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    model_accuracies[model_name] = train_accuracy\n",
    "    print(f'{model_name} Training Accuracy: {train_accuracy:.2f}')\n",
    "\n",
    "# Find the model with the highest accuracy\n",
    "best_model_name = max(model_accuracies, key=model_accuracies.get)\n",
    "best_model_accuracy = model_accuracies[best_model_name]\n",
    "\n",
    "# Print the selected model\n",
    "print(f'\\nSelected Model: {best_model_name} (Training Accuracy: {best_model_accuracy:.2f})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb4da888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.92      0.83       415\n",
      "           1       0.72      0.42      0.53       213\n",
      "\n",
      "    accuracy                           0.75       628\n",
      "   macro avg       0.74      0.67      0.68       628\n",
      "weighted avg       0.74      0.75      0.73       628\n",
      "\n",
      "\n",
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      1.00      0.80       415\n",
      "           1       0.00      0.00      0.00       213\n",
      "\n",
      "    accuracy                           0.66       628\n",
      "   macro avg       0.33      0.50      0.40       628\n",
      "weighted avg       0.44      0.66      0.53       628\n",
      "\n",
      "\n",
      "K-Nearest Neighbors Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.82      0.78       415\n",
      "           1       0.55      0.43      0.49       213\n",
      "\n",
      "    accuracy                           0.69       628\n",
      "   macro avg       0.65      0.63      0.63       628\n",
      "weighted avg       0.68      0.69      0.68       628\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nicole Mascarenhas\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Nicole Mascarenhas\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Nicole Mascarenhas\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Nicole Mascarenhas\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.98      0.82       415\n",
      "           1       0.82      0.19      0.31       213\n",
      "\n",
      "    accuracy                           0.71       628\n",
      "   macro avg       0.76      0.59      0.56       628\n",
      "weighted avg       0.74      0.71      0.65       628\n",
      "\n",
      "\n",
      "XGBoost Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.89      0.82       415\n",
      "           1       0.68      0.43      0.53       213\n",
      "\n",
      "    accuracy                           0.74       628\n",
      "   macro avg       0.72      0.66      0.67       628\n",
      "weighted avg       0.73      0.74      0.72       628\n",
      "\n",
      "\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "Neural Network Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      1.00      0.80       415\n",
      "           1       0.00      0.00      0.00       213\n",
      "\n",
      "    accuracy                           0.66       628\n",
      "   macro avg       0.33      0.50      0.40       628\n",
      "weighted avg       0.44      0.66      0.53       628\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nicole Mascarenhas\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Nicole Mascarenhas\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Nicole Mascarenhas\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define a dictionary of models\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=3),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'XGBoost': xgb.XGBClassifier(random_state=42),\n",
    "    'Neural Network': model\n",
    "}\n",
    "\n",
    "# Loop through models and evaluate each one\n",
    "for model_name, model in models.items():\n",
    "    if model_name == 'Neural Network':\n",
    "        y_train_pred = (model.predict(X_train) > 0.5).astype(int)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_train_pred = model.predict(X_train)\n",
    "    \n",
    "    # Calculate classification report\n",
    "    report = classification_report(y_train, y_train_pred)\n",
    "    \n",
    "    # Print the classification report\n",
    "    print(f'{model_name} Classification Report:\\n{report}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9564b4d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
